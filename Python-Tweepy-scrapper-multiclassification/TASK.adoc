= SCRAP TWITTER API

Use case: +
we want to get a specific bunch of tweets from their given IDs. We want these twwets specifically because these IDS are provided with a sentiment analysis labels,
so we want to recover the text associated to these sentiments.


== Create dev environement on Twitter
Ongoing - create a dev account on https://developer.twitter.com[twitter dev] +
create an App with customer and access tokens

== Create local environement
**Done**- Create a virtual environement `nlpbase` with python3.6 +
**Done**- Install tweepy. The syntax for declaring API in tweepy is +

**auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)** +
**auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)**

== Procedure

Create a scraper that will

 - parse the Twitter API and recover the tweet text only from the ID given in the `BIDU.txt` file and merge these texts with sentiment labels
 - for this exercise we will assume that you will have to send your request by batches as the API won't accept a request of a 10.000 and we have network issues, so we want to write sequentially on the disk each time we get a batch of tweets

the deliverable is a simple cmd line tool


